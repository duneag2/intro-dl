{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 2024 Winter Introduction to Deep Learning\n","### Based on Prof. Oh's Youtube Lecture\n","https://youtube.com/playlist?list=PLvbUC2Zh5oJvByu9KL82bswYT2IKf0K1M\n","\n","> Assignment #8\n","\n","\n","*   Youtube Lecture #32-35\n","*   Written by Seungeun Lee"],"metadata":{"id":"YcXb0XLEvHns"}},{"cell_type":"markdown","source":["## 1. Autoencoder\n","*     Reference. https://dacon.io/codeshare/4551\n","*     FashionMNIST dataset"],"metadata":{"id":"qM2kM5G7BYZr"}},{"cell_type":"markdown","source":["#### (1) Extract latent vectors & Reconstruct image w/ Autoencoder (AE)"],"metadata":{"id":"Hdber_YkbUSn"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torchvision import transforms, datasets\n","\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from matplotlib import cm\n","import numpy as np\n","\n","# Import"],"metadata":{"id":"11Ih6xyA5NoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCH = 10\n","BATCH_SIZE = 64\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","print(\"Using Device:\", DEVICE)\n","\n","# Settings"],"metadata":{"id":"LF3Dn5b_5Ni2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainset = datasets.FashionMNIST(\n","    root      = './.data/',\n","    train     = True,\n","    download  = True,\n","    transform = transforms.ToTensor()\n",")\n","train_loader = torch.utils.data.DataLoader(\n","    dataset     = trainset,\n","    batch_size  = BATCH_SIZE,\n","    shuffle     = True,\n","    num_workers = 2\n",")\n","\n","# Fashion MNIST"],"metadata":{"id":"ipCaOFjQ7Y_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder, self).__init__()\n","\n","        # Encoder (input: 28*28 image -> 3 as a latent vector)\n","        self.encoder = nn.Sequential(\n","            nn.Linear(28*28, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 12),\n","            nn.ReLU(),\n","            nn.Linear(12, 3),\n","        )\n","        # Decoder (from latent vector (size: 3) -> decode it to 28*28 size image)\n","        self.decoder = nn.Sequential(\n","            nn.Linear(3, 12),\n","            nn.ReLU(),\n","            nn.Linear(12, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 28*28),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return encoded, decoded"],"metadata":{"id":"ftRUJDWQ7Y4A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["autoencoder = Autoencoder().to(DEVICE)\n","optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.005)\n","criterion = nn.MSELoss()\n","\n","# Optimizer and Loss"],"metadata":{"id":"qmUmWqV-7Yye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["view_data = trainset.data[:5].view(-1, 28*28)\n","view_data = view_data.type(torch.FloatTensor)/255.\n","\n","# Flatten the image"],"metadata":{"id":"w0XeLU8s7Ytd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(autoencoder, train_loader):\n","    autoencoder.train()\n","    for step, (x, label) in enumerate(train_loader):\n","        x = x.view(-1, 28*28).to(DEVICE)\n","        y = x.view(-1, 28*28).to(DEVICE)\n","        label = label.to(DEVICE)\n","\n","        encoded, decoded = autoencoder(x)\n","\n","        loss = criterion(decoded, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","# Loss = MSE(Decoded, y)"],"metadata":{"id":"MaFANjmp7Yn_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(1, EPOCH+1):\n","    train(autoencoder, train_loader)\n","\n","    test_x = view_data.to(DEVICE)\n","    _, decoded_data = autoencoder(test_x)\n","\n","    f, a = plt.subplots(2, 5, figsize=(5, 2))\n","    print(\"[Epoch {}]\".format(epoch))\n","    for i in range(5):\n","        img = np.reshape(view_data.data.numpy()[i],(28, 28))\n","        a[0][i].imshow(img, cmap='gray')\n","        a[0][i].set_xticks(()); a[0][i].set_yticks(())\n","\n","    for i in range(5):\n","        img = np.reshape(decoded_data.to(\"cpu\").data.numpy()[i], (28, 28))\n","        a[1][i].imshow(img, cmap='gray')\n","        a[1][i].set_xticks(()); a[1][i].set_yticks(())\n","    plt.show()"],"metadata":{"id":"6bx146Jg7YiU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### (2) Image Denoising w/ AE"],"metadata":{"id":"hrAsSGhPbZAO"}},{"cell_type":"code","source":["def add_noise(img):\n","    noise = torch.randn(img.size()) * 0.2\n","    noisy_img = img + noise\n","    return noisy_img"],"metadata":{"id":"ivGBFM0F9BaB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(autoencoder, train_loader):\n","    autoencoder.train()\n","    avg_loss = 0\n","    for step, (x, label) in enumerate(train_loader):\n","        noisy_x = add_noise(x)\n","        noisy_x = noisy_x.view(-1, 28*28).to(DEVICE)\n","        y = x.view(-1, 28*28).to(DEVICE)\n","\n","        label = label.to(DEVICE)\n","        encoded, decoded = autoencoder(noisy_x)\n","\n","        loss = criterion(decoded, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        avg_loss += loss.item()\n","    return avg_loss / len(train_loader)"],"metadata":{"id":"38sHoNs1bxTZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(1, EPOCH+1):\n","    loss = train(autoencoder, train_loader)\n","    print(\"[Epoch {}] loss:{}\".format(epoch, loss))"],"metadata":{"id":"jlkqDPyxbxOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testset = datasets.FashionMNIST(\n","    root      = './.data/',\n","    train     = False, # Unseen test dataset\n","    download  = True,\n","    transform = transforms.ToTensor()\n",")\n","\n","sample_data = testset.data[0].view(-1, 28*28)\n","sample_data = sample_data.type(torch.FloatTensor)/255.\n","\n","original_x = sample_data[0]\n","noisy_x = add_noise(original_x).to(DEVICE)\n","_, recovered_x = autoencoder(noisy_x)"],"metadata":{"id":"ehnx8keVcaoO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f, a = plt.subplots(1, 3, figsize=(15, 15))\n","\n","original_img = np.reshape(original_x.to(\"cpu\").data.numpy(), (28, 28))\n","noisy_img = np.reshape(noisy_x.to(\"cpu\").data.numpy(), (28, 28))\n","recovered_img = np.reshape(recovered_x.to(\"cpu\").data.numpy(), (28, 28))\n","\n","# original image\n","a[0].set_title('Original')\n","a[0].imshow(original_img, cmap='gray')\n","\n","# original image w/ noise\n","a[1].set_title('Noisy')\n","a[1].imshow(noisy_img, cmap='gray')\n","\n","# recoveredimage\n","a[2].set_title('Recovered')\n","a[2].imshow(recovered_img, cmap='gray')\n","\n","plt.show()"],"metadata":{"id":"kyfoJQKtcjfB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question 1. Explain the code of the '1. Autoencoder' section \"briefly\"."],"metadata":{"id":"O3WZDNNDcrlZ"}},{"cell_type":"code","source":["# 1. Load Fashion MNIST\n","# 2. Make model. With 4 Layers, it changes 28x28 image to 3 latent vectors\n","# 3. Use Adam optimizer and MSE Loss (Decoded, y)\n","# 4. Learning"],"metadata":{"id":"eRgLUBG1IGwb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Principal Component Analysis [PCA]\n","*    Reference. https://romg2.github.io/mlguide/12_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C-06.-%EC%B0%A8%EC%9B%90%EC%B6%95%EC%86%8C-PCA/\n","\n"],"metadata":{"id":"Qb5wK4jY3Aw9"}},{"cell_type":"markdown","source":["#### Question 2. What is PCA in \"mathematical\" perspective? Google it and write your own answer."],"metadata":{"id":"Ai-zS87adcvB"}},{"cell_type":"code","source":["# 선형대수적으로, 입력->공분산 행렬->고윳값 분해->고유벡터 추출->입력을 변환\n","# Linear한 차원 축소 기법으로, 이 역시 입력 데이터를 적은 차원으로 표현 가능\n","# 그러나 Linear라는 것 자체가 딥러닝에 비해 한계가 있을 수 밖에 없다"],"metadata":{"id":"fZuFdLkyIuor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import warnings"],"metadata":{"id":"FqZefh_T5OaX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","mpl.rc('font', family='NanumGothic')\n","mpl.rc('axes', unicode_minus=False)\n","\n","sns.set(font=\"NanumGothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n","plt.rc(\"figure\", figsize=(10,8))\n","\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"wqK3pwpIdPHu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","\n","iris = load_iris()\n","\n","columns = ['sepal_length','sepal_width','petal_length','petal_width']\n","iris_df = pd.DataFrame(data = iris.data, columns = columns)\n","iris_df[\"target\"] = iris.target\n","\n","iris_df.head()"],"metadata":{"id":"qsCdDs8odPDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["markers = [\"^\", \"s\", \"o\"]\n","\n","# 0:setosa, 1:versicolor, 2:virginica\n","for i, marker in enumerate(markers):\n","    x_axis_data = iris_df[iris_df['target']==i]['sepal_length']\n","    y_axis_data = iris_df[iris_df['target']==i]['sepal_width']\n","    plt.scatter(x_axis_data, y_axis_data, marker=marker, label=iris.target_names[i])\n","\n","plt.legend()\n","plt.xlabel('sepal length')\n","plt.ylabel('sepal width')\n","plt.show()"],"metadata":{"id":"Q8q0uSiwdO-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","iris_f_scaled = StandardScaler().fit_transform(iris_df.iloc[:,:-1])"],"metadata":{"id":"fao_xeLjdO7L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","\n","pca = PCA(n_components = 2) # of principal components = 2\n","\n","pca.fit(iris_f_scaled)\n","iris_pca = pca.transform(iris_f_scaled)\n","\n","print(f\"scaled: {iris_f_scaled.shape}\")\n","print(f\"pca: {iris_pca.shape}\")"],"metadata":{"id":"tCPDEzSgdaF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pca_columns=['pca_component_1','pca_component_2']\n","\n","iris_df_pca = pd.DataFrame(iris_pca, columns = pca_columns)\n","iris_df_pca['target'] = iris.target\n","\n","iris_df_pca.head(3)"],"metadata":{"id":"llvnZNRLdaB2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["markers = [\"^\", \"s\", \"o\"]\n","\n","# 0:setosa, 1:versicolor, 2:virginica\n","for i, marker in enumerate(markers):\n","    x_axis_data = iris_df_pca[iris_df_pca['target']==i]['pca_component_1']\n","    y_axis_data = iris_df_pca[iris_df_pca['target']==i]['pca_component_2']\n","    plt.scatter(x_axis_data, y_axis_data, marker=marker,label=iris.target_names[i])\n","\n","plt.legend()\n","plt.xlabel('pca_component_1')\n","plt.ylabel('pca_component_2')\n","plt.show()"],"metadata":{"id":"WT4IyLp6dZ7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pca.explained_variance_ratio_) ## Although we implemented PCA, we can still explain majority of the data"],"metadata":{"id":"vhFQKy9Xd05w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QkEXE3Usd01m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rTqah8txd0xW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9IvZjI6Td0s7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question 3.\n","### Autoencoder reduces the dimension of the data w/ deep learning methods.\n","### PCA does the same thing in mathematically linear way.\n","### In this context, Autoencoder is a _ _ _ _ _ _ _ _ _ PCA.\n","### Hint: n _ _ l _ _ _ _ _"],"metadata":{"id":"_Pk46rI2NIhF"}},{"cell_type":"code","source":["# Nonlinear"],"metadata":{"id":"wmlhFHTNerfn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Variational Autoencoder (VAE)\n","\n","\n","\n","\n","\n"],"metadata":{"id":"V9sYztYRAGNO"}},{"cell_type":"markdown","source":["### Question 4 (Optional).\n","### Read the following document, run the whole code and write an explanation.\n","### https://github.com/Jackson-Kang/Pytorch-VAE-tutorial/blob/master/01_Variational_AutoEncoder.ipynb"],"metadata":{"id":"47Lz-iLAAWOS"}},{"cell_type":"code","source":[],"metadata":{"id":"jqA_pfdaBN0F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Seq2Seq, Attention, Transformer"],"metadata":{"id":"Nhzalt5CgZzC"}},{"cell_type":"markdown","source":["### Question 4 (Optional).\n","### Choose one of the following document. Read it, run the whole code and write and explanation.\n","### (1) Machine Translation using Attention and Seq2Seq: https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html\n","### (2) Understanding Transformer: https://wikidocs.net/156986\n","### (3) Chatbot based on Text Similarity (Transformer): https://wikidocs.net/157970"],"metadata":{"id":"0gaLQ4dahhA0"}},{"cell_type":"code","source":[],"metadata":{"id":"wx026812BNuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VFCJ_YjpCn9g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The End."],"metadata":{"id":"spc48rNHQnYL"}},{"cell_type":"markdown","source":["##### Please upload your Colab file @Github https://github.com/duneag2/intro-dl/tree/main/Assignment8\n","\n","*   First, make your folder by your name (e.g. seungeun)\n","*   Then upload your \"Jupyter Notebook\" file under that directory\n","\n","###### Need Help?\n","\n","\n","\n","*   Please refer to this link https://yeko90.tistory.com/entry/%ED%8C%8C%EC%9D%B4%EC%8D%AC-colab%EC%BD%94%EB%9E%A9%EC%97%90%EC%84%9C-%EC%95%95%EC%B6%95%ED%8C%8C%EC%9D%BC-%ED%92%80%EA%B8%B0 OR\n","*   Just save your Jupyter Notebook (.ipynb) file in here (colab) and upload via 'Add file' - 'Upload files' https://nthree.tistory.com/60"],"metadata":{"id":"iMNBVkjiS7D9"}},{"cell_type":"code","source":[],"metadata":{"id":"XzVGuer0S9Oh"},"execution_count":null,"outputs":[]}]}