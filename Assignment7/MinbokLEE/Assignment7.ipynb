{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2024 Winter Introduction to Deep Learning\n",
        "### Based on Prof. Oh's Youtube Lecture\n",
        "https://youtube.com/playlist?list=PLvbUC2Zh5oJvByu9KL82bswYT2IKf0K1M\n",
        "\n",
        "> Assignment #7\n",
        "\n",
        "\n",
        "*   Youtube Lecture #27-31\n",
        "*   Written by Seungeun Lee"
      ],
      "metadata": {
        "id": "YcXb0XLEvHns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Recurrent Neural Network [RNN]\n",
        "*     Reference. https://data-science.tistory.com/67"
      ],
      "metadata": {
        "id": "qM2kM5G7BYZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "11Ih6xyA5NoG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 5\n",
        "hidden_size = 8"
      ],
      "metadata": {
        "id": "LF3Dn5b_5Ni2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (batch_size, time_steps, input_size)\n",
        "inputs = torch.Tensor(1, 10, 5)"
      ],
      "metadata": {
        "id": "ipCaOFjQ7Y_j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cell = nn.RNN(input_size, hidden_size, batch_first=True) # defines the RNN architecture\n",
        "# batch_first = True -> indicates that the first dimension stands for the batch size\n",
        "# if False, the input should be (10, 5), i.e. (time_steps, input_size), getting rid of the batch_size"
      ],
      "metadata": {
        "id": "ftRUJDWQ7Y4A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, _status = cell(inputs)"
      ],
      "metadata": {
        "id": "qmUmWqV-7Yye"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0XeLU8s7Ytd",
        "outputId": "7d8811f5-5153-4d45-bc7c-31d2e56bd9df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(_status.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaFANjmp7Yn_",
        "outputId": "a4f7e10a-1e30-4b52-c0fe-9b6c7fcdcd2f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeper RNN\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs2 = torch.Tensor(1, 10, 5)\n",
        "cell2 = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True) # num_layers = 2 -> deeper RNN (default: 1)\n",
        "outputs2, _status2 = cell2(inputs2)\n",
        "print(outputs2.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps) -> only returns the last layer\n",
        "print(_status2.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 2 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bx146Jg7YiU",
        "outputId": "94b66e04-0d37-4c23-a21c-b1141ba5cd2b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([2, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeper RNN\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs3 = torch.Tensor(1, 10, 5)\n",
        "cell3 = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 3, batch_first=True) # num_layers = 3 -> deeper RNN (default: 1)\n",
        "outputs3, _status3 = cell3(inputs3)\n",
        "print(outputs3.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps) -> only returns the last layer\n",
        "print(_status3.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 3 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivGBFM0F9BaB",
        "outputId": "744bf2da-a073-4b6b-b2fc-423b7411d685"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([3, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Long Short Term Memory [LSTM]"
      ],
      "metadata": {
        "id": "Qb5wK4jY3Aw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeper LSTM -- we only need to change nn.RNN into nn.LSTM\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs4 = torch.Tensor(1, 10, 5)\n",
        "cell4 = nn.LSTM(input_size = 5, hidden_size = 8, num_layers = 4, batch_first=True) # num_layers = 4 -> deeper LSTM (default: 1)\n",
        "outputs4, (h4, c4) = cell4(inputs4)\n",
        "print(outputs4.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps) -> only returns the last layer\n",
        "print(h4.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 4 layers\n",
        "print(c4.shape) # cell state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 4 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqZefh_T5OaX",
        "outputId": "1e2854e6-f570-434b-f359-9034eb3fc1e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([4, 1, 8])\n",
            "torch.Size([4, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.\n",
        "### Write a code for LSTM having 10 internal layers (num_layers = 10) and change the input size into (5, 50, 5). Please stick to the format provided. Check if the size of the output, hidden, and cell state are calculated properly."
      ],
      "metadata": {
        "id": "n64ndo75_Nfw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IpVz1YapCZ5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2. Describe the limiations of (Vanilla) RNN and how LSTM overcomes these limitations."
      ],
      "metadata": {
        "id": "7GDml6Jn5xIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9rbYbX4uAig_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Gated Recurrent Unit [GRU]"
      ],
      "metadata": {
        "id": "V9sYztYRAGNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3.\n",
        "### Write a code for GRU having 5 internal layers (num_layers = 5) and change the input size into (3, 45, 7). (Change the input_size adequately) Please stick to the format provided. Check if the size of output and hidden state are calculated properly.\n",
        "### Hint: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html Its implementation is similar to that of RNN."
      ],
      "metadata": {
        "id": "47Lz-iLAAWOS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqA_pfdaBN0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wx026812BNuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. On your Own"
      ],
      "metadata": {
        "id": "seqJ1hGC3KXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 4. Choose one or two from the following documents:**\n",
        "\n",
        "\n",
        "*    **News topic Classification with RNN:** https://glanceyes.com/entry/PyTorch%EB%A1%9C-RNN-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%ED%98%84%ED%95%B4%EB%B3%B4%EA%B8%B0-AG-NEWS-%EB%89%B4%EC%8A%A4-%EA%B8%B0%EC%82%AC-%EC%A3%BC%EC%A0%9C-%EB%B6%84%EB%A5%98\n",
        "*    **NAVER Movie Review Classification with LSTM:** https://wikidocs.net/217687\n",
        "*   **IMDB Review Classification with GRU:** https://wikidocs.net/217083\n",
        "\n",
        "#### Read it and run the whole code. Write a simplified explanation for each cell.\n"
      ],
      "metadata": {
        "id": "_8C9KcjF3Ygs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note. https://wikidocs.net/book/2788 and https://wikidocs.net/book/2155 provide lots of interesting codes!"
      ],
      "metadata": {
        "id": "BEl8LO2q4vr2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VFCJ_YjpCn9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The End."
      ],
      "metadata": {
        "id": "spc48rNHQnYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Please upload your Colab file @Github https://github.com/duneag2/intro-dl/tree/main/Assignment7\n",
        "\n",
        "*   First, make your folder by your name (e.g. seungeun)\n",
        "*   Then upload your \"Jupyter Notebook\" file under that directory\n",
        "\n",
        "###### Need Help?\n",
        "\n",
        "\n",
        "\n",
        "*   Please refer to this link https://yeko90.tistory.com/entry/%ED%8C%8C%EC%9D%B4%EC%8D%AC-colab%EC%BD%94%EB%9E%A9%EC%97%90%EC%84%9C-%EC%95%95%EC%B6%95%ED%8C%8C%EC%9D%BC-%ED%92%80%EA%B8%B0 OR\n",
        "*   Just save your Jupyter Notebook (.ipynb) file in here (colab) and upload via 'Add file' - 'Upload files' https://nthree.tistory.com/60"
      ],
      "metadata": {
        "id": "iMNBVkjiS7D9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XzVGuer0S9Oh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}