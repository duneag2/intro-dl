{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2024 Winter Introduction to Deep Learning\n",
        "### Based on Prof. Oh's Youtube Lecture\n",
        "https://youtube.com/playlist?list=PLvbUC2Zh5oJvByu9KL82bswYT2IKf0K1M\n",
        "\n",
        "> Assignment #7\n",
        "\n",
        "\n",
        "*   Youtube Lecture #27-31\n",
        "*   Written by Seungeun Lee"
      ],
      "metadata": {
        "id": "YcXb0XLEvHns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Recurrent Neural Network [RNN]\n",
        "*     Reference. https://data-science.tistory.com/67"
      ],
      "metadata": {
        "id": "qM2kM5G7BYZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "11Ih6xyA5NoG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 5\n",
        "hidden_size = 8"
      ],
      "metadata": {
        "id": "LF3Dn5b_5Ni2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (batch_size, time_steps, input_size)\n",
        "inputs = torch.Tensor(1, 10, 5)"
      ],
      "metadata": {
        "id": "ipCaOFjQ7Y_j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cell = nn.RNN(input_size, hidden_size, batch_first=True) # defines the RNN architecture\n",
        "# batch_first = True -> indicates that the first dimension stands for the batch size\n",
        "# if False, the input should be (10, 5), i.e. (time_steps, input_size), getting rid of the batch_size"
      ],
      "metadata": {
        "id": "ftRUJDWQ7Y4A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, _status = cell(inputs)"
      ],
      "metadata": {
        "id": "qmUmWqV-7Yye"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0XeLU8s7Ytd",
        "outputId": "72bd6753-278a-449b-e3e4-5a7261e34b22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(_status.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaFANjmp7Yn_",
        "outputId": "661b2bb0-8691-468b-bd80-097ceddc607a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeper RNN\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs2 = torch.Tensor(1, 10, 5)\n",
        "cell2 = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True) # num_layers = 2 -> deeper RNN (default: 1)\n",
        "outputs2, _status2 = cell2(inputs2)\n",
        "print(outputs2.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps) -> only returns the last layer\n",
        "print(_status2.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 2 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bx146Jg7YiU",
        "outputId": "dcda9443-24a6-48c2-a69d-97af7fc6a9fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([2, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeper RNN\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs3 = torch.Tensor(1, 10, 5)\n",
        "cell3 = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 3, batch_first=True) # num_layers = 3 -> deeper RNN (default: 1)\n",
        "outputs3, _status3 = cell3(inputs3)\n",
        "print(outputs3.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps) -> only returns the last layer\n",
        "print(_status3.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 3 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivGBFM0F9BaB",
        "outputId": "1ac97067-cb14-471c-e124-8d31f57d4e96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([3, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Long Short Term Memory [LSTM]"
      ],
      "metadata": {
        "id": "Qb5wK4jY3Aw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeper LSTM -- we only need to change nn.RNN into nn.LSTM\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs4 = torch.Tensor(1, 10, 5)\n",
        "cell4 = nn.LSTM(input_size = 5, hidden_size = 8, num_layers = 4, batch_first=True) # num_layers = 4 -> deeper LSTM (default: 1)\n",
        "outputs4, (h4, c4) = cell4(inputs4)\n",
        "print(outputs4.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps) -> only returns the last layer\n",
        "print(h4.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 4 layers\n",
        "print(c4.shape) # cell state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 4 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqZefh_T5OaX",
        "outputId": "0d7acc85-0d33-4cf1-ec0f-7f21ea0b1c84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([4, 1, 8])\n",
            "torch.Size([4, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.\n",
        "### Write a code for LSTM having 10 internal layers (num_layers = 10) and change the input size into (5, 50, 5). Please stick to the format provided. Check if the size of the output, hidden, and cell state are calculated properly."
      ],
      "metadata": {
        "id": "n64ndo75_Nfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.Tensor(5, 50, 5) # (batch size, time step, input size)\n",
        "cell = nn.LSTM(input_size = 5, hidden_size = 8, num_layers = 10, batch_first=True)\n",
        "output, (h, c) = cell(input)\n",
        "print(output.shape)\n",
        "print(h.shape)\n",
        "print(c.shape)"
      ],
      "metadata": {
        "id": "IpVz1YapCZ5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e99312-6e87-447d-f7cb-f6c6c15eec24"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 50, 8])\n",
            "torch.Size([10, 5, 8])\n",
            "torch.Size([10, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2. Describe the limiations of (Vanilla) RNN and how LSTM overcomes these limitations."
      ],
      "metadata": {
        "id": "7GDml6Jn5xIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla RNN의 한계점\n",
        "### 1. backpropagation을 하는 과정에서 기울기의 값이 1 이하이기 때문에 gradient vanishing problem이 나타난다.\n",
        "### 2. feed-forward를 하는 과정에서 time-step이 뒤로 갈수록 맨 앞의 정보가 손실되는 long-term dependency 문제가 발생하게 된다.\n",
        "\n",
        "## LSTM이 RNN의 문제를 극복한 방법\n",
        "### 1. LSTM은 원래 RNN 구조에 여러 gate를 추가하여 RNN의 단점을 극복한 모델입니다. 여러 gate가 추가 되었는데, 추가된 gate는 다음과 같습니다.\n",
        "#### 1) input gate : input gate는 현재 time step에 입력된 값에 얼마나 가중치를 줄 것인지 결정하는 gate입니다.\n",
        "#### 2) forget gate : forget gate는 이전 cell state의 정보를 얼마나 잊을지 결정하는 gate 입니다.\n",
        "#### 3) output gate : output gate는 다음 은닉층의 값으로 얼마나 정보를 줄지 결정하는 gate 입니다.\n",
        "#### 4) gate gate : 이는 RNN에서 했던 기본 연산과 동일한 연산입니다.\n",
        "#### 5) cell state : forget gate와 이전의 cell state를 곱해주고, input gate와 gate gate를 곱해준 두 값을 더해주어 계산합니다.\n",
        "\n",
        "### 2. LSTM은 1과 같은 구조를 이용하여 RNN에서 발생한 long-term dependency 문제를 해결할 수 있습니다.\n",
        "### 3. 또한, cell state를 이용하여 LSTM은 backpropagation에서 기울기가 감소 또는 매우 커지는 현상을 막을 수 있습니다."
      ],
      "metadata": {
        "id": "XXQu_xyEgY-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Gated Recurrent Unit [GRU]"
      ],
      "metadata": {
        "id": "V9sYztYRAGNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3.\n",
        "### Write a code for GRU having 5 internal layers (num_layers = 5) and change the input size into (3, 45, 7). (Change the input_size adequately) Please stick to the format provided. Check if the size of output and hidden state are calculated properly.\n",
        "### Hint: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html Its implementation is similar to that of RNN."
      ],
      "metadata": {
        "id": "47Lz-iLAAWOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_g = torch.Tensor(3, 45, 7) # (batch size, time step, input size)\n",
        "cell_g = nn.GRU(input_size = 7, hidden_size = 8, num_layers = 5, batch_first=True)\n",
        "output_g, h_g = cell_g(input_g)\n",
        "print(output_g.shape)\n",
        "print(h_g.shape)"
      ],
      "metadata": {
        "id": "jqA_pfdaBN0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7862eec-a946-45d9-c5f2-b6a4bf3ac246"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 45, 8])\n",
            "torch.Size([5, 3, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. On your Own"
      ],
      "metadata": {
        "id": "seqJ1hGC3KXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 4. Choose one or two from the following documents:**\n",
        "\n",
        "\n",
        "*    **News topic Classification with RNN:** https://glanceyes.com/entry/PyTorch%EB%A1%9C-RNN-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%ED%98%84%ED%95%B4%EB%B3%B4%EA%B8%B0-AG-NEWS-%EB%89%B4%EC%8A%A4-%EA%B8%B0%EC%82%AC-%EC%A3%BC%EC%A0%9C-%EB%B6%84%EB%A5%98\n",
        "*    **NAVER Movie Review Classification with LSTM:** https://wikidocs.net/217687\n",
        "*   **IMDB Review Classification with GRU:** https://wikidocs.net/217083\n",
        "\n",
        "#### Read it and run the whole code. Write a simplified explanation for each cell.\n"
      ],
      "metadata": {
        "id": "_8C9KcjF3Ygs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note. https://wikidocs.net/book/2788 and https://wikidocs.net/book/2155 provide lots of interesting codes!"
      ],
      "metadata": {
        "id": "BEl8LO2q4vr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. GRU를 이용한 IMDB 리뷰 분류"
      ],
      "metadata": {
        "id": "kwzA8RtMwAqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk # 기본적인 자연어 처리를 위한 라이브러리\n",
        "import torch\n",
        "import urllib.request # 데이터 셋을 불러오기 위한 url 관련 라이브러리\n",
        "from tqdm import tqdm # 반복문에서 진행률을 prograss bar로 표현해주고 남은 시간 정보를 알려주는 라이브러리\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize # 언어 토큰화를 하기 위한 라이브러리\n",
        "from sklearn.model_selection import train_test_split # 데스트 데이터와 트레인 데이터를 나누기 위한 라이브러리"
      ],
      "metadata": {
        "id": "Fi81M44xwH1q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugR3cWopyMsF",
        "outputId": "ace6ff24-3b4b-412b-c688-1b5b3aef8ec2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/pytorch-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/IMDB%20Dataset.csv\", filename=\"IMDB Dataset.csv\")\n",
        "# IMDB 데이터 셋을 불러오는 코드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zILf87JwKaN",
        "outputId": "8317a33d-219b-46e7-ab22-852271b5629d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('IMDB Dataset.csv', <http.client.HTTPMessage at 0x782d6ff887c0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('IMDB Dataset.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YQxWqkncwaHY",
        "outputId": "c29d9d94-87d7-44a1-d035-e3dd3fc4f2a9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a972a369-8a4c-4535-8d3c-f81544987104\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a972a369-8a4c-4535-8d3c-f81544987104')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a972a369-8a4c-4535-8d3c-f81544987104 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a972a369-8a4c-4535-8d3c-f81544987104');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-00196e91-f4ce-4dc3-82f8-036c59933a1b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00196e91-f4ce-4dc3-82f8-036c59933a1b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-00196e91-f4ce-4dc3-82f8-036c59933a1b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_544524bf-9d0e-4439-bf5a-9b46c272b263\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_544524bf-9d0e-4439-bf5a-9b46c272b263 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APsRn3z353KW",
        "outputId": "bf11af8a-bbb2-4aff-be9b-d2d1f7e69e69"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('결측치 여부:', df.isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTXGM9iJwhSQ",
        "outputId": "e4ca1b07-921c-434a-e478-e7b95d120f50"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결측치 여부: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['sentiment'].replace(['positive','negative'],[1, 0])\n",
        "df.head()\n",
        "# positive와 negative로 이루어져 있는 레이블을 1과 0으로 변환해주는 코드이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ci-EasGL56Yw",
        "outputId": "1cd7909d-b0eb-49e4-d484-19f8383bdc25"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-709208c7-3756-423d-99f0-d76fe428674a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-709208c7-3756-423d-99f0-d76fe428674a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-709208c7-3756-423d-99f0-d76fe428674a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-709208c7-3756-423d-99f0-d76fe428674a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4063f968-52f8-4233-a5d8-c4b688d5c022\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4063f968-52f8-4233-a5d8-c4b688d5c022')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4063f968-52f8-4233-a5d8-c4b688d5c022 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# positive\\uc640 negative\\ub85c \\uc774\\ub8e8\\uc5b4\\uc838 \\uc788\\ub294 \\ub808\\uc774\\ube14\\uc744 1\\uacfc 0\\uc73c\\ub85c \\ubcc0\\ud658\\ud574\\uc8fc\\ub294 \\ucf54\\ub4dc\\uc774\\ub2e4\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \\\"has got all the polari\\\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\",\n          \"Petter Mattei's \\\"Love in the Time of Money\\\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.\",\n          \"I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \\\"sexy\\\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \\\"Devil Wears Prada\\\" and more interesting than \\\"Superman\\\" a great comedy to go see with friends.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = df['review']\n",
        "y_data = df['sentiment']"
      ],
      "metadata": {
        "id": "_irksp-Pw_tZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.5, random_state=0, stratify=y_data)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.2, random_state=0, stratify=y_train)\n",
        "\n",
        "print('--------훈련 데이터의 비율-----------')\n",
        "print(f'부정 리뷰 = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
        "print(f'긍정 리뷰 = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
        "print('--------검증 데이터의 비율-----------')\n",
        "print(f'부정 리뷰 = {round(y_valid.value_counts()[0]/len(y_valid) * 100,3)}%')\n",
        "print(f'긍정 리뷰 = {round(y_valid.value_counts()[1]/len(y_valid) * 100,3)}%')\n",
        "print('--------테스트 데이터의 비율-----------')\n",
        "print(f'부정 리뷰 = {round(y_test.value_counts()[0]/len(y_test) * 100,3)}%')\n",
        "print(f'긍정 리뷰 = {round(y_test.value_counts()[1]/len(y_test) * 100,3)}%')\n",
        "# train_test_split 함수를 이용하여 train, validation, test 데이터 셋을 나누는 코드\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Z8sFFLwuf1",
        "outputId": "c4c3b3a2-a84a-410c-e6de-5abb14f6c54f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------훈련 데이터의 비율-----------\n",
            "부정 리뷰 = 50.0%\n",
            "긍정 리뷰 = 50.0%\n",
            "--------검증 데이터의 비율-----------\n",
            "부정 리뷰 = 50.0%\n",
            "긍정 리뷰 = 50.0%\n",
            "--------테스트 데이터의 비율-----------\n",
            "부정 리뷰 = 50.0%\n",
            "긍정 리뷰 = 50.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentences):\n",
        "  tokenized_sentences = []\n",
        "  for sent in tqdm(sentences):\n",
        "    tokenized_sent = word_tokenize(sent) # 워드 토큰화 진행\n",
        "    tokenized_sent = [word.lower() for word in tokenized_sent] # 토큰화한 단어를 소문자로 변환\n",
        "    tokenized_sentences.append(tokenized_sent) # 토큰화한 단어를 문장 배열에 넣어줌\n",
        "  return tokenized_sentences\n",
        "\n",
        "tokenized_X_train = tokenize(X_train)\n",
        "tokenized_X_valid = tokenize(X_valid)\n",
        "tokenized_X_test = tokenize(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D0DsnXAxGw4",
        "outputId": "df674276-4182-4e79-a1b4-85e0e570e86c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:45<00:00, 443.38it/s]\n",
            "100%|██████████| 5000/5000 [00:09<00:00, 546.57it/s]\n",
            "100%|██████████| 25000/25000 [00:41<00:00, 604.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화된 샘플을 2개 출력하는 코드\n",
        "for sent in tokenized_X_train[:2]:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLsUyVPkyQMw",
        "outputId": "ca97afda-8b04-466e-b1e0-db395cc60cc2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['have', 'you', 'ever', ',', 'or', 'do', 'you', 'have', ',', 'a', 'pet', 'who', \"'s\", 'been', 'with', 'you', 'through', 'thick', 'and', 'thin', ',', 'who', 'you', \"'d\", 'be', 'lost', 'without', ',', 'and', 'who', 'you', 'love', 'no', 'matter', 'what', '?', 'betcha', 'never', 'thought', 'they', 'feel', 'the', 'same', 'way', 'about', 'you', '!', '<', 'br', '/', '>', '<', 'br', '/', '>', 'wonderful', ',', 'wonderful', 'family', 'film', '.', 'if', 'you', 'have', 'a', 'soft', 'spot', 'for', 'animals', ',', 'this', 'is', 'guaranteed', 'to', 'make', 'you', 'cry', 'no', 'matter', 'your', 'age', '.', 'i', 'used', 'to', 'watch', 'this', 'movie', 'all', 'the', 'time', 'when', 'i', 'was', 'a', 'little', 'kid', ',', 'and', 'i', 'find', 'that', 'now', ',', 'at', 'age', 'sixteen', ',', 'i', 'love', 'it', 'as', 'much', 'as', 'i', 'did', 'then', '.', 'i', 'could', 'never', 'decide', 'on', 'a', 'favorite', 'character', 'then', ',', 'and', 'i', 'still', 'do', \"n't\", 'think', 'i', 'can', '!', 'i', 'love', 'all', 'three', 'of', 'the', 'animals', '.', 'the', 'dialogue', 'seems', 'very', 'real', 'and', 'comfortable', ',', 'like', 'a', 'loving', ',', 'but', 'feuding', 'family', '.', 'i', 'do', 'love', 'chance', ',', 'and', 'how', 'at', 'the', 'end', 'he', 'says', 'that', 'he', 'has', 'a', 'family', 'at', 'last', '.', 'cheesy', ',', 'yes', ',', 'but', 'one', 'must', 'remember', 'that', 'this', 'is', 'meant', 'to', 'be', 'a', 'family', 'film', ',', 'and', 'it', 'fulfills', 'that', 'role', 'perfectly', '.', 'sassy', 'has', 'just', 'the', 'perfect', 'dose', 'of', '``', 'sassiness', \"''\", 'and', 'shadow', 'is', 'the', 'perfect', 'leader/role', 'model', 'to', 'the', 'young', ',', 'adventurous', 'chance.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'animals', 'way', 'outshine', 'the', 'humans', ',', 'but', 'of', 'course', 'most', 'of', 'the', 'teary', 'moments', 'are', 'to', 'be', 'had', 'during', 'an', 'interaction', 'with', 'them', '(', 'ie', '.', 'rescuing', 'molly', ',', 'and', 'the', 'end', ')', '.', 'not', 'to', 'mention', 'the', 'incredible', 'soundtrack', 'that', 'gives', 'each', 'moment', 'even', 'more', 'emotion', ',', 'and', 'an', 'accompanying', 'heart-swelling', 'feeling', '.', 'i', 'give', 'this', '9/10', '.', 'to', 'be', 'compared', 'to', '(', 'and', 'even', 'rated', 'better', 'than', ')', 'cats', 'and', 'dogs', 'and', 'babe', '.']\n",
            "['i', 'hate', 'football', '!', '!', 'i', 'hate', 'football', 'fans', '!', 'i', 'hate', 'cars', '!', 'but', 'this', 'film', 'was', 'the', 'funniest', 'thing', 'i', 'have', 'seen', 'in', 'quite', 'some', 'time', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'was', 'given', 'the', 'great', 'opportunity', 'to', 'see', 'this', 'film', 'at', 'the', 'weekend', ',', 'and', 'all', 'i', 'have', 'to', 'say', 'is', 'i', 'laughed', 'till', 'i', 'cried', ',', 'and', 'when', 'is', 'it', 'going', 'to', 'be', 'available', 'in', 'the', 'uk', 'and', 'denmark', '.', 'girls', ',', 'this', 'is', 'one', 'football', 'film', 'you', 'will', 'need', 'to', 'see', ',', 'its', 'hilarious', '!', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'fact', 'that', 'this', 'film', 'started', 'out', 'as', 'some', 'crazy', 'commercial', 'for', 'a', 'telephone', 'company', 'is', 'just', 'amazing', ',', 'the', 'guys', 'may', 'not', 'be', 'well', 'known', 'actors', ',', 'but', 'this', 'is', 'good', 'down', 'to', 'earth', 'real', 'humour', ',', 'with', 'real', 'people', ',', 'and', 'i', 'for', 'one', 'applaud', 'them', 'for', 'taking', 'this', 'to', 'the', 'screen.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'well', 'done', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "for sent in tokenized_X_train:\n",
        "    for word in sent:\n",
        "      word_list.append(word)\n",
        "\n",
        "word_counts = Counter(word_list)\n",
        "print('총 단어수 :', len(word_counts))\n",
        "# 토큰화 된 훈련 데이터로부터 정수 인코딩을 하기 위핸서 데이터에 존재하는\n",
        "# 단어 종류의 총 개수와 각 단어에 대한 등장 빈도를 카운트 하는 코드이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DZVKcoRycld",
        "outputId": "08102d0f-c4a7-49e5-836d-a4fafb7d266e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 단어수 : 100586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터에서의 단어 the의 등장 횟수 :', word_counts['the'])\n",
        "print('훈련 데이터에서의 단어 love의 등장 횟수 :', word_counts['love'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzQ97eNbzPVp",
        "outputId": "ad330bba-95ad-47c8-9771-9de30891aafc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터에서의 단어 the의 등장 횟수 : 265697\n",
            "훈련 데이터에서의 단어 love의 등장 횟수 : 4984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "print('등장 빈도수 상위 10개 단어')\n",
        "print(vocab[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJOcWcjizB18",
        "outputId": "e4e68608-4263-4de1-fee0-dad7f0ae8ecc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "등장 빈도수 상위 10개 단어\n",
            "['the', ',', '.', 'a', 'and', 'of', 'to', 'is', '/', '>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 3\n",
        "total_cnt = len(word_counts) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfg1FENWzVh-",
        "outputId": "d2ffac6e-4951-4d5b-942d-d5af13569cdb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 100586\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 61877\n",
            "단어 집합에서 희귀 단어의 비율: 61.51651323245779\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.3294254426463437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
        "vocab_size = total_cnt - rare_cnt\n",
        "vocab = vocab[:vocab_size]\n",
        "print('단어 집합의 크기 :', len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTp1oYbJzgdL",
        "outputId": "ae28af9f-00cf-469c-e76f-17446f9b517a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 38709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "word_to_index['<PAD>'] = 0\n",
        "word_to_index['<UNK>'] = 1\n",
        "\n",
        "for index, word in enumerate(vocab) :\n",
        "  word_to_index[word] = index + 2\n",
        "\n",
        "vocab_size = len(word_to_index)\n",
        "print('패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)\n",
        "# 패딩 토큰인 <PAD>에는 정수 0을 할당시켜 준다.\n",
        "# 모르는 단어 즉, OOV(Out Of Vocabulary)가 발생할 경우를 대비하여 <UNK> 토큰에 정수 1을 할당시켜 준다.\n",
        "# 나머지 단어에도 각각의 정수를 할당해준다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5s_KuA8zl6u",
        "outputId": "d17610f5-8575-4b24-8b12-4c64b4784081"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 : 38711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
        "  encoded_X_data = []\n",
        "  for sent in tokenized_X_data:\n",
        "    index_sequences = []\n",
        "    for word in sent:\n",
        "      try:\n",
        "          index_sequences.append(word_to_index[word])\n",
        "      except KeyError:\n",
        "          index_sequences.append(word_to_index['<UNK>'])\n",
        "    encoded_X_data.append(index_sequences)\n",
        "  return encoded_X_data\n",
        "\n",
        "encoded_X_train = texts_to_sequences(tokenized_X_train, word_to_index)\n",
        "encoded_X_valid = texts_to_sequences(tokenized_X_valid, word_to_index)\n",
        "encoded_X_test = texts_to_sequences(tokenized_X_test, word_to_index)\n",
        "# word_to_index 함수를 이용하여 데이터를 정수 인코딩 해주는 코드이다."
      ],
      "metadata": {
        "id": "wlpo6zxA0PmI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩이 진행된 학습 데이터의 샘플 2개를 출력하는 코드\n",
        "for sent in encoded_X_train[:2]:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M73CIEo31Dct",
        "outputId": "27ba2a6a-c9d9-4a85-aee4-772f68dc3190"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[38, 29, 140, 3, 52, 54, 29, 38, 3, 5, 3406, 47, 19, 95, 22, 29, 161, 4059, 6, 1741, 3, 47, 29, 293, 39, 469, 218, 3, 6, 47, 29, 134, 71, 532, 61, 59, 25184, 130, 214, 44, 249, 2, 189, 114, 58, 29, 41, 12, 13, 10, 11, 12, 13, 10, 11, 384, 3, 384, 253, 26, 4, 57, 29, 38, 5, 2280, 1587, 23, 1477, 3, 17, 9, 5775, 8, 111, 29, 1440, 71, 532, 141, 677, 4, 16, 343, 8, 126, 17, 24, 43, 2, 75, 63, 16, 20, 5, 137, 538, 3, 6, 16, 172, 18, 164, 3, 42, 677, 12075, 3, 16, 134, 14, 21, 89, 21, 16, 83, 110, 4, 16, 94, 130, 1124, 30, 5, 494, 121, 110, 3, 6, 16, 145, 54, 31, 120, 16, 73, 41, 16, 134, 43, 301, 7, 2, 1477, 4, 2, 425, 204, 66, 168, 6, 3964, 3, 50, 5, 1961, 3, 25, 19699, 253, 4, 16, 54, 134, 580, 3, 6, 105, 42, 2, 152, 36, 544, 18, 36, 55, 5, 253, 42, 247, 4, 933, 3, 421, 3, 25, 40, 227, 407, 18, 17, 9, 965, 8, 39, 5, 253, 26, 3, 6, 14, 17326, 18, 233, 872, 4, 8000, 55, 53, 2, 416, 4967, 7, 33, 1, 32, 6, 2669, 9, 2, 416, 1, 2144, 8, 2, 208, 3, 8988, 13008, 12, 13, 10, 11, 12, 13, 10, 11, 2, 1477, 114, 1, 2, 1732, 3, 25, 7, 276, 103, 7, 2, 25185, 404, 35, 8, 39, 80, 305, 46, 3778, 22, 112, 28, 6428, 4, 13009, 5279, 3, 6, 2, 152, 27, 4, 34, 8, 727, 2, 1055, 713, 18, 398, 256, 539, 70, 65, 1375, 3, 6, 46, 8753, 1, 546, 4, 16, 215, 17, 2959, 4, 8, 39, 1079, 8, 28, 6, 70, 1482, 143, 92, 27, 4610, 6, 2299, 6, 5706, 4]\n",
            "[16, 735, 2344, 41, 41, 16, 735, 2344, 467, 41, 16, 735, 1903, 41, 25, 17, 26, 20, 2, 1588, 165, 16, 38, 128, 15, 198, 62, 75, 4, 12, 13, 10, 11, 12, 13, 10, 11, 16, 20, 360, 2, 100, 1359, 8, 77, 17, 26, 42, 2, 2394, 3, 6, 43, 16, 38, 8, 147, 9, 16, 1445, 2395, 16, 3268, 3, 6, 63, 9, 14, 184, 8, 39, 1320, 15, 2, 2382, 6, 9728, 4, 520, 3, 17, 9, 40, 2344, 26, 29, 97, 354, 8, 77, 3, 109, 604, 41, 12, 13, 10, 11, 12, 13, 10, 11, 2, 206, 18, 17, 26, 652, 60, 21, 62, 912, 1877, 23, 5, 7155, 1010, 9, 53, 483, 3, 2, 451, 210, 34, 39, 91, 594, 170, 3, 25, 17, 9, 64, 202, 8, 786, 168, 1155, 3, 22, 168, 102, 3, 6, 16, 23, 40, 6916, 112, 23, 628, 17, 8, 2, 4968, 12, 13, 10, 11, 12, 13, 10, 11, 91, 237, 41]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('리뷰의 최대 길이 :',max(len(review) for review in encoded_X_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, encoded_X_train))/len(encoded_X_train))\n",
        "plt.hist([len(review) for review in encoded_X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "# 서로 다른 길이의 데이터들을 동일한 길이로 일치시켜주는 패딩 작업을 진행해야 한다.\n",
        "# 이를 위해서 훈련 데이터의 최대 길이, 평균 길이, 데이터의 길이 분포를 확인하는 코드이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "4W0E4ppA1NON",
        "outputId": "24ddb71b-de1b-40df-8bf4-6f60e30dfb9f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 2818\n",
            "리뷰의 평균 길이 : 279.1958\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))\n",
        "# 모델이 처리할 수 있도록 데이터릐 길이를 일정하게 만들어 주어야 한다.\n",
        "# 특정 길이 변수를 max_len으로 정하고, 대부분의 리뷰 내용이 잘리지 않도록 할 수 있는 최적의\n",
        "# max_len을 찾기 위해서 전체 샘플 중 길이가 max_len 이하인 샘플이 비율이 얼마인지 출력해주는 함수를 이용하여 확인해준다."
      ],
      "metadata": {
        "id": "u99xUkRO2BPH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500\n",
        "below_threshold_len(max_len, encoded_X_train)\n",
        "# max_len을 500으로 할 경우 약 87%의 샘플이 그대로 보존되는 것을 볼 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OA1UQnc2dCP",
        "outputId": "7c231534-15f7-4104-ee4d-357d2faadf7b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 500 이하인 샘플의 비율: 87.795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sentences, max_len):\n",
        "  features = np.zeros((len(sentences), max_len), dtype=int)\n",
        "  for index, sentence in enumerate(sentences):\n",
        "    if len(sentence) != 0:\n",
        "      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
        "  return features\n",
        "\n",
        "padded_X_train = pad_sequences(encoded_X_train, max_len=max_len)\n",
        "padded_X_valid = pad_sequences(encoded_X_valid, max_len=max_len)\n",
        "padded_X_test = pad_sequences(encoded_X_test, max_len=max_len)\n",
        "\n",
        "print('훈련 데이터의 크기 :', padded_X_train.shape)\n",
        "print('검증 데이터의 크기 :', padded_X_valid.shape)\n",
        "print('테스트 데이터의 크기 :', padded_X_test.shape)\n",
        "# 위에서 정한 max_len = 500과 pad_sequneces 함수를 정의하여 모든 데이터의 길이를 500으로 맞춰주는 코드이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prY9V0I91m0l",
        "outputId": "23f2ed3d-cf15-45b6-c668-4a80cbe8a9cb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : (20000, 500)\n",
            "검증 데이터의 크기 : (5000, 500)\n",
            "테스트 데이터의 크기 : (25000, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qk5Jvoyi2yJd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available() # GPU 사용이 가능한지 확인하는 코드이다.\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTOyv2Dx25BY",
        "outputId": "744a55e7-725d-461b-8d71-fa27ab9ddc99"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu와 cuda 중 다음 기기로 학습함: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_tensor = torch.tensor(np.array(y_train))\n",
        "valid_label_tensor = torch.tensor(np.array(y_valid))\n",
        "test_label_tensor = torch.tensor(np.array(y_test))\n",
        "print(train_label_tensor[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP8M0EzP4J3y",
        "outputId": "882088fa-b993-4118-8cb1-f7b5f5670111"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim) # output_dim = 분류하고자하는 카테고리의 개수\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_length) == (32, 500)\n",
        "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim) == (32, 500, 100) == (데이터의 개수, 문장길이, 단어 벡터의 차원)\n",
        "        gru_out, hidden = self.gru(embedded)  # gru_out: (batch_size, seq_length, hidden_dim), hidden: (1, batch_size, hidden_dim)\n",
        "        last_hidden = hidden.squeeze(0)  # (batch_size, hidden_dim)\n",
        "        logits = self.fc(last_hidden)  # (batch_size, output_dim)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "fzLfX_3u3HWn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_train = torch.tensor(padded_X_train).to(torch.int64)\n",
        "train_dataset = torch.utils.data.TensorDataset(encoded_train, train_label_tensor)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
        "\n",
        "encoded_test = torch.tensor(padded_X_test).to(torch.int64)\n",
        "test_dataset = torch.utils.data.TensorDataset(encoded_test, test_label_tensor)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=1)\n",
        "\n",
        "encoded_valid = torch.tensor(padded_X_valid).to(torch.int64)\n",
        "valid_dataset = torch.utils.data.TensorDataset(encoded_valid, valid_label_tensor)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=1)"
      ],
      "metadata": {
        "id": "rdZnNrOD3_ef"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(train_dataloader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))\n",
        "# 배치의 개수를 32개로 설정했기 때문에 20000/32 = 625 이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS1guuSs6IZw",
        "outputId": "c6ec8a22-101a-472c-ad4c-1828d9ec734e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 배치의 수 : 625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "hidden_dim = 128 # hidden layer의 dimension을 128로 설정해준다.\n",
        "output_dim = 2 # 1과 0을 분류하는 모델이므로 output dimension을 2로 설정해준다.\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10\n",
        "\n",
        "model = TextClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "model.to(device) # 모델의 객체를 선언하는 코드이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ynvFnAM6Vl4",
        "outputId": "18b808ce-df86-403b-b2c5-df8f4073bc8d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassifier(\n",
              "  (embedding): Embedding(38711, 100)\n",
              "  (gru): GRU(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Q7eraslg6nLK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(logits, labels):\n",
        "    # _, predicted = torch.max(logits, 1)\n",
        "    predicted = torch.argmax(logits, dim=1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "prAw1JMq6qMq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, valid_dataloader, criterion, device):\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # 데이터로더로부터 배치 크기만큼의 데이터를 연속으로 로드\n",
        "        for batch_X, batch_y in valid_dataloader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            # 모델에 입력값을 넣어서 모델의 예측값을 계산한다.\n",
        "            logits = model(batch_X)\n",
        "\n",
        "            # 위에서 정한 손실함수를 이용하여 손실값을 계산한다.\n",
        "            loss = criterion(logits, batch_y)\n",
        "\n",
        "            # 정확도와 손실을 계산함\n",
        "            val_loss += loss.item()\n",
        "            val_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
        "            val_total += batch_y.size(0)\n",
        "\n",
        "    val_accuracy = val_correct / val_total\n",
        "    val_loss /= len(valid_dataloader)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "YbGtH2-H7CZI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_dataloader:\n",
        "        # Forward pass\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        # batch_X.shape == (batch_size, max_len)\n",
        "        logits = model(batch_X)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, batch_y)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy and loss\n",
        "        train_loss += loss.item()\n",
        "        train_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
        "        train_total += batch_y.size(0)\n",
        "\n",
        "    train_accuracy = train_correct / train_total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # 검증 손실이 최소일 때 체크포인트 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEWDI-ef7Smj",
        "outputId": "e8e41dcb-2573-47d3-ac15-c3a013e8879d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 0.6964, Train Accuracy: 0.5072\n",
            "Validation Loss: 0.6925, Validation Accuracy: 0.5090\n",
            "Validation loss improved from inf to 0.6925. 체크포인트를 저장합니다.\n",
            "Epoch 2/5:\n",
            "Train Loss: 0.6904, Train Accuracy: 0.5170\n",
            "Validation Loss: 0.7010, Validation Accuracy: 0.5104\n",
            "Epoch 3/5:\n",
            "Train Loss: 0.6756, Train Accuracy: 0.5485\n",
            "Validation Loss: 0.6886, Validation Accuracy: 0.5358\n",
            "Validation loss improved from 0.6925 to 0.6886. 체크포인트를 저장합니다.\n",
            "Epoch 4/5:\n",
            "Train Loss: 0.5892, Train Accuracy: 0.6896\n",
            "Validation Loss: 0.5361, Validation Accuracy: 0.7488\n",
            "Validation loss improved from 0.6886 to 0.5361. 체크포인트를 저장합니다.\n",
            "Epoch 5/5:\n",
            "Train Loss: 0.4372, Train Accuracy: 0.8062\n",
            "Validation Loss: 0.4284, Validation Accuracy: 0.8106\n",
            "Validation loss improved from 0.5361 to 0.4284. 체크포인트를 저장합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 로드\n",
        "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
        "\n",
        "# 모델을 device에 올립니다.\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fygraPO7Yfn",
        "outputId": "a49986c2-375e-4944-a7bd-39e19328f5e1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassifier(\n",
              "  (embedding): Embedding(38711, 100)\n",
              "  (gru): GRU(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터에 대한 정확도와 손실 계산하는 코드\n",
        "val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
        "\n",
        "print(f'Best model validation loss: {val_loss:.4f}')\n",
        "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "son7kuei7blH",
        "outputId": "8ea9d77b-fa18-4d5d-8a38-c63985e7c70f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model validation loss: 0.4284\n",
            "Best model validation accuracy: 0.8106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터에 대한 정확도와 손실 계산하는 코드\n",
        "test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n",
        "\n",
        "print(f'Best model test loss: {test_loss:.4f}')\n",
        "print(f'Best model test accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw3Qxwzj7dGL",
        "outputId": "7d610ad7-6c00-42ee-c2aa-7795c1f543ce"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model test loss: 0.4352\n",
            "Best model test accuracy: 0.8150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_tag = {0 : '부정', 1 : '긍정'}\n",
        "\n",
        "def predict(text, model, word_to_index, index_to_tag):\n",
        "    # 모델 평가 모드\n",
        "    model.eval()\n",
        "\n",
        "    # 토큰화 및 정수 인코딩. OOV 문제 발생 시 <UNK> 토큰에 해당하는 인덱스 1 할당\n",
        "    tokens = word_tokenize(text)\n",
        "    token_indices = [word_to_index.get(token.lower(), 1) for token in tokens]\n",
        "\n",
        "    # 리스트를 텐서로 변경\n",
        "    input_tensor = torch.tensor([token_indices], dtype=torch.long).to(device)  # (1, seq_length)\n",
        "\n",
        "    # 모델의 예측\n",
        "    with torch.no_grad(): # 기울기 값을 계산하지 않도록 설정해주는 코드이다.\n",
        "        logits = model(input_tensor)  # (1, output_dim)\n",
        "\n",
        "    # 레이블 인덱스 예측\n",
        "    _, predicted_index = torch.max(logits, dim=1)  # (1,)\n",
        "\n",
        "    # 인덱스와 매칭되는 카테고리 문자열로 변경\n",
        "    predicted_tag = index_to_tag[predicted_index.item()]\n",
        "\n",
        "    return predicted_tag"
      ],
      "metadata": {
        "id": "Zt4ZQyWd7kZt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = \"This movie was just way too overrated. The fighting was not professional and in slow motion. I was expecting more from a 200 million budget movie. The little sister of T.Challa was just trying too hard to be funny. The story was really dumb as well. Don't watch this movie if you are going because others say its great unless you are a Black Panther fan or Marvels fan.\"\n",
        "\n",
        "predict(test_input, model, word_to_index, index_to_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4nx8Eir17ts5",
        "outputId": "25166049-5082-4b1e-c83d-115f7dee36a2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'부정'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = \" I was lucky enough to be included in the group to see the advanced screening in Melbourne on the 15th of April, 2012. And, firstly, I need to say a big thank-you to Disney and Marvel Studios. Now, the film... how can I even begin to explain how I feel about this film? It is, as the title of this review says a 'comic book triumph'. I went into the film with very, very high expectations and I was not disappointed. Seeing Joss Whedon's direction and envisioning of the film come to life on the big screen is perfect. The script is amazingly detailed and laced with sharp wit a humor. The special effects are literally mind-blowing and the action scenes are both hard-hitting and beautifully choreographed.\"\n",
        "\n",
        "predict(test_input, model, word_to_index, index_to_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O7y2zwZd7ufA",
        "outputId": "25e3b618-cf03-4291-cd5a-c27c36476b4d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'긍정'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The End."
      ],
      "metadata": {
        "id": "spc48rNHQnYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Please upload your Colab file @Github https://github.com/duneag2/intro-dl/tree/main/Assignment7\n",
        "\n",
        "*   First, make your folder by your name (e.g. seungeun)\n",
        "*   Then upload your \"Jupyter Notebook\" file under that directory\n",
        "\n",
        "###### Need Help?\n",
        "\n",
        "\n",
        "\n",
        "*   Please refer to this link https://yeko90.tistory.com/entry/%ED%8C%8C%EC%9D%B4%EC%8D%AC-colab%EC%BD%94%EB%9E%A9%EC%97%90%EC%84%9C-%EC%95%95%EC%B6%95%ED%8C%8C%EC%9D%BC-%ED%92%80%EA%B8%B0 OR\n",
        "*   Just save your Jupyter Notebook (.ipynb) file in here (colab) and upload via 'Add file' - 'Upload files' https://nthree.tistory.com/60"
      ],
      "metadata": {
        "id": "iMNBVkjiS7D9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XzVGuer0S9Oh"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}