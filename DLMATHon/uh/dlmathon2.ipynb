{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1UOV1xWVvbQWJHJvYcCSf2xQo_PKVwJup",
      "authorship_tag": "ABX9TyPr1lVShj/Ac3tYvWyNP2B7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duneag2/intro-dl/blob/main/DLMATHon/uh/dlmathon2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyheif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nci3cj0-hpnp",
        "outputId": "32a463bf-0aed-48e6-9921-69ead311ca85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyheif\n",
            "  Downloading pyheif-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyheif) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->pyheif) (2.22)\n",
            "Downloading pyheif-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/9.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/9.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyheif\n",
            "Successfully installed pyheif-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WtN5FT3Z3qB",
        "outputId": "d826b761-1134-4ba0-bc05-67473711326a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -qq '/content/drive/MyDrive/ddubuk_cls.zip' -d '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "zf2V9fgvagcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6042a9f9-6888-44e4-bdf2-70e1d6ea86c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/drive/MyDrive/ddubuk/test/ddubuk/IMG_0974.HEIC? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/drive/MyDrive/ddubuk/test/ddubuk/IMG_1847.HEIC? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/drive/MyDrive/ddubuk/test/ddubuk/IMG_1848.HEIC? [y]es, [n]o, [A]ll, [N]one, [r]ename: r\n",
            "new name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ddubuk/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HEh8OTJT7Jv",
        "outputId": "2e74f843-e787-427d-b38d-b211a887f789"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ddubuk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "import random\n",
        "import pyheif"
      ],
      "metadata": {
        "id": "ePM7xRskdvnp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
      ],
      "metadata": {
        "id": "BPieqX2tT4f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af46661-d033-45f9-cd1e-030c9590bc45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.3.1+cu121  Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "train_dir = '/content/drive/MyDrive/ddubuk/train'\n",
        "test_dir = '/content/drive/MyDrive/ddubuk/test'\n",
        "\n",
        "# Convert images to a common format (JPEG)\n",
        "def convert_images_to_jpg(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            filepath = os.path.join(root, file)\n",
        "            new_filepath = os.path.splitext(filepath)[0] + '.jpg'\n",
        "\n",
        "            if file.lower().endswith('.heic'):\n",
        "                try:\n",
        "                    heif_file = pyheif.read(filepath)\n",
        "                    image = Image.frombytes(\n",
        "                        heif_file.mode,\n",
        "                        heif_file.size,\n",
        "                        heif_file.data,\n",
        "                        \"raw\",\n",
        "                        heif_file.mode,\n",
        "                        heif_file.stride,\n",
        "                    )\n",
        "                    image = image.convert('RGB')\n",
        "                    image.save(new_filepath, \"JPEG\")\n",
        "                    os.remove(filepath)\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not convert {filepath}: {e}\")\n",
        "\n",
        "            elif not file.lower().endswith('.jpg'):\n",
        "                try:\n",
        "                    img = Image.open(filepath)\n",
        "                    img = img.convert('RGB')\n",
        "                    img.save(new_filepath, 'JPEG')\n",
        "                    os.remove(filepath)\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not convert {filepath}: {e}\")\n",
        "\n",
        "convert_images_to_jpg(train_dir)\n",
        "convert_images_to_jpg(test_dir)"
      ],
      "metadata": {
        "id": "OkaBGxzdhCpo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for training\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "5Ychp9phhIXB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from folders\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
        "\n",
        "# Split the train_dataset into train and validation datasets\n",
        "train_indices, val_indices = train_test_split(list(range(len(train_dataset))), test_size=0.2, stratify=train_dataset.targets)\n",
        "\n",
        "train_set = Subset(train_dataset, train_indices)\n",
        "val_set = Subset(train_dataset, val_indices)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2cPg8XehMXi",
        "outputId": "cd9cc085-5283-4ad6-f9b3-d1300bd9df93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet50 model\n",
        "model_ft = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer to match the number of classes (ddubuk and not_ddubuk)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)  # 2 classes: ddubuk and not_ddubuk\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "metadata": {
        "id": "GMUcmD8KhMUh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "THsxR0fvhMRk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                # Track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnoU853HhMIz",
        "outputId": "89d50194-b956-4f9e-9c55-8096a27d4be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    test_acc = running_corrects.double() / len(test_loader.dataset)\n",
        "    print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Test the model\n",
        "test_model(model_ft, test_loader)"
      ],
      "metadata": {
        "id": "-WcTKTnuhTky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ddubuk/model_resnet50.pth')"
      ],
      "metadata": {
        "id": "TEkzBxbehVoh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}